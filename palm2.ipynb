{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from google.cloud import aiplatform\n",
    "from sklearn.metrics import classification_report\n",
    "from vertexai.language_models import ChatModel, InputOutputTextPair\n",
    "from utils import html_parsing_ncbi, html_parsing_n2c2, get_classification_report, get_digit, get_macro_average_f1\n",
    "\n",
    "aiplatform.init(project='xxx-xxx-xxx')\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You will have to setup a project on Google Cloud that enables Vertex AI API, and replace 'xxx-xxx-xxx' with your own project ID. The free trial period of Google Cloud has limited quota for Vertex AI API for PaLM2 model Bison per minute (~60 per minute). If you encounter quota exceeded error, please try again after that minute and continue from where you left off in the for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 NCBI-Disease Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_df = pd.read_csv('data/NER/NCBI-disease/test_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_ncbi_disease(sentence: str, shot: int = 0) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    chat = chat_model.start_chat(\n",
    "        context=\"\"\"\n",
    "                \"TASK: the task is to extract disease entities in a sentence.\"\n",
    "                \"INPUT: the input is a sentence.\"\n",
    "                \"OUTPUT: the output is an HTML that highlights all the disease entities in the sentence. \\\n",
    "                        The highlighting should only use HTML tags <span style=\\\"background-color: #FFFF00\\\"> and </span> and no other tags.\"\n",
    "                \"\"\",\n",
    "        examples=[\n",
    "            InputOutputTextPair(\n",
    "                input_text=\"In summary , inactivation of the murine ATP7B gene produces a form of cirrhotic liver disease that resembles Wilson disease in humans and the toxic milk phenotype in the mouse . .\",\n",
    "                output_text='In summary , inactivation of the murine ATP7B gene produces a form of <span style=\"background-color: #FFFF00\">cirrhotic liver disease</span> \\\n",
    "                            that resembles <span style=\"background-color: #FFFF00\">Wilson disease</span> in humans and the toxic milk phenotype in the mouse . .',\n",
    "            ),\n",
    "        ] if shot == 1 else []\n",
    "    )\n",
    "\n",
    "    time_start = time.time()\n",
    "    response = chat.send_message(\n",
    "        sentence, **parameters\n",
    "    )\n",
    "    time_end = time.time()\n",
    "\n",
    "    return response.text, time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(ncbi_df), 1)):\n",
    "    if (i + 1) % 20 == 0: # in case of quota limit error per minute\n",
    "        time.sleep(65)\n",
    "    ncbi_df.loc[i, 'html_palm2_zero_shot'], ncbi_df.loc[i, 'palm2_zero_shot_time'] = get_ner_ncbi_disease(ncbi_df.loc[i, 'text'], 0)\n",
    "    ncbi_df.loc[i, 'html_palm2_one_shot'], ncbi_df.loc[i, 'palm2_one_shot_time'] = get_ner_ncbi_disease(ncbi_df.loc[i, 'text'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: you can just load the llm output from the csv file instead of running the above code\n",
    "# ncbi_df = pd.read_csv(\"data/NER/NCBI-disease/test_200_palm2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_df['gt_labels'], ncbi_df['palm2_zero_shot_labels'] = html_parsing_ncbi(ncbi_df, 'html_palm2_zero_shot')\n",
    "_, ncbi_df['palm2_one_shot_labels'] = html_parsing_ncbi(ncbi_df, 'html_palm2_one_shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_report(ncbi_df, 'gt_labels', 'palm2_one_shot_labels', 'strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_report(ncbi_df, 'gt_labels', 'palm2_one_shot_labels', 'lenient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average PaLM 2 zero-shot prediction time: {ncbi_df['palm2_zero_shot_time'].mean():.2f} seconds\")\n",
    "print(f\"Average PaLM 2 one-shot prediction time: {ncbi_df['palm2_one_shot_time'].mean():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inference results\n",
    "ncbi_df.to_csv('data/NER/NCBI-disease/test_200_palm2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 2018 n2c2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_df = pd.read_csv('data/NER/2018_n2c2/test_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_2018_n2c2(sentence: str, shot: int = 0) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    chat = chat_model.start_chat(\n",
    "        context=\"\"\"\n",
    "                \"TASK: the task is to extract disease entities in a sentence. The entity type includes Form, Route, Frequency, Dosage, Strength, Duration, Reason, Ade, Drug.\"\n",
    "                \"INPUT: the input is a sentence.\"\n",
    "                \"OUTPUT: the output is an HTML that highlights all the disease entities in the sentence in different colors: Form(#FF0000), Route(#FFA500), Frequency(#FFFF00), Dosage(#00FF00), Strength(#0000FF), Duration(#800080), Reason(#FFC0CB), Ade(#964B00), Drug(#808080) in hex code. \\\n",
    "                        The highlighting should only use HTML tags <span style=\\\"background-color: #XXXXXX\\\"> and </span> and no other tags.\"\n",
    "                \"\"\",\n",
    "        examples=[\n",
    "            InputOutputTextPair(\n",
    "                input_text=\"Vitamin D 400 unit Tablet Sig : Two ( 2 ) Tablet PO once a day .\",\n",
    "                output_text='<span style=\"background-color: #808080\">Vitamin D</span> <span style=\"background-color: #0000FF\">400 unit</span> <span style=\"background-color: #FF0000\">Tablet</span> Sig : <span style=\"background-color: #00FF00\">Two ( 2 )</span> <span style=\"background-color: #FF0000\">Tablet</span> <span style=\"background-color: #FFA500\">PO</span> <span style=\"background-color: #FFFF00\">once a day</span> .',\n",
    "            ),\n",
    "        ] if shot == 1 else []\n",
    "    )\n",
    "\n",
    "    time_start = time.time()\n",
    "    response = chat.send_message(\n",
    "        sentence, **parameters\n",
    "    )\n",
    "    time_end = time.time()\n",
    "\n",
    "    return response.text, time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(n2c2_df), 1)):\n",
    "    if (i + 1) % 20 == 0: # in case of quota limit error per minute\n",
    "        time.sleep(65)\n",
    "    n2c2_df.loc[i, 'html_palm2_zero_shot'], n2c2_df.loc[i, 'palm2_zero_shot_time'] = get_ner_2018_n2c2(n2c2_df.loc[i, 'text'], 0)\n",
    "    n2c2_df.loc[i, 'html_palm2_one_shot'], n2c2_df.loc[i, 'palm2_one_shot_time'] = get_ner_2018_n2c2(n2c2_df.loc[i, 'text'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: you can just load the llm output from the csv file instead of running the above code\n",
    "# n2c2_df = pd.read_csv(\"data/NER/2018_n2c2/test_200_palm2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_df['gt_labels'], n2c2_df['palm2_zero_shot_labels'] = html_parsing_n2c2(n2c2_df, 'html_palm2_zero_shot')\n",
    "_, n2c2_df['palm2_one_shot_labels'] = html_parsing_n2c2(n2c2_df, 'html_palm2_one_shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_report(n2c2_df, 'gt_labels', 'palm2_one_shot_labels', 'strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_macro_average_f1(get_classification_report(n2c2_df, 'gt_labels', 'palm2_one_shot_labels', 'strict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classification_report(n2c2_df, 'gt_labels', 'palm2_one_shot_labels', 'lenient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_macro_average_f1(get_classification_report(n2c2_df, 'gt_labels', 'palm2_one_shot_labels', 'lenient'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average PaLM 2 zero-shot prediction time: {n2c2_df['palm2_zero_shot_time'].mean():.2f} seconds\")\n",
    "print(f\"Average PaLM 2 one-shot prediction time: {n2c2_df['palm2_one_shot_time'].mean():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inference results\n",
    "n2c2_df.to_csv('data/NER/2018_n2c2/test_200_palm2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RE (Relation Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 2018 n2c2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2c2_df = pd.read_csv('data/ER/2018_n2c2/test_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_2018_n2c2(sentence: str, shot: int = 0) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    chat = chat_model.start_chat(\n",
    "        context=\"\"\"\n",
    "                \"TASK: the task is to classify relations for a sentence.\"\n",
    "                \"INPUT: the input is a sentence where the entities are labeled within [E${X}] and [E${X}/] in a sentence, where X is an integer representing an unique entity.\"\n",
    "                \"OUTPUT: your task is to select one out of the nine types of relations ('STRENGTH-DRUG', 'ROUTE-DRUG', 'FREQUENCY-DRUG', 'FORM-DRUG', 'DOSAGE-DRUG', \\\n",
    "                        'REASON-DRUG', 'DURATION-DRUG', 'ADE-DRUG', and 'No relation').\"\n",
    "                \"\"\",\n",
    "        examples=[\n",
    "            InputOutputTextPair(\n",
    "                input_text=\"[E2] Docusate/Sodium [E2/] ( Liquid ) 100/mg PO BID/:/PRN [E1] constipation [E1/] 4 .\",\n",
    "                output_text='REASON-DRUG',\n",
    "            ),\n",
    "        ] if shot == 1 else []\n",
    "    )\n",
    "\n",
    "    time_start = time.time()\n",
    "    response = chat.send_message(\n",
    "        sentence, **parameters\n",
    "    )\n",
    "    time_end = time.time()\n",
    "\n",
    "    return response.text, time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(n2c2_df), 1)):\n",
    "    if (i + 1) % 20 == 0: # in case of quota limit error per minute\n",
    "        time.sleep(65)\n",
    "    n2c2_df.loc[i, 'palm2_zero_shot'], n2c2_df.loc[i, 'palm2_zero_shot_time'] = get_re_2018_n2c2(n2c2_df.iloc[i]['text'], 0)\n",
    "    n2c2_df.loc[i, 'palm2_one_shot'], n2c2_df.loc[i, 'palm2_one_shot_time'] = get_re_2018_n2c2(n2c2_df.iloc[i]['text'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of ' ' if any\n",
    "n2c2_df['palm2_zero_shot'] = n2c2_df['palm2_zero_shot'].apply(lambda x: x[1:-1] if \"'\" in x else x)\n",
    "n2c2_df['palm2_one_shot'] = n2c2_df['palm2_one_shot'].apply(lambda x: x[1:-1] if \"'\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get digit label while considering failed LLM outputs as 'No relation'\n",
    "n2c2_df['labels'] = n2c2_df['labels'].apply(get_digit)\n",
    "n2c2_df['palm2_zero_shot_labels'] = n2c2_df['palm2_zero_shot'].apply(get_digit)\n",
    "n2c2_df['palm2_one_shot_labels'] = n2c2_df['palm2_one_shot'].apply(get_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: you can just load the llm output from the csv file instead of running the above code\n",
    "# n2c2_df = pd.read_csv(\"data/ER/2018_n2c2/test_200_palm2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = n2c2_df['labels'].tolist()\n",
    "y_pred = n2c2_df['palm2_one_shot_labels'].tolist()\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average PaLM 2 zero-shot prediction time: {n2c2_df['palm2_zero_shot_time'].mean():.2f} seconds\")\n",
    "print(f\"Average PaLM 2 one-shot prediction time: {n2c2_df['palm2_one_shot_time'].mean():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inference results\n",
    "n2c2_df.to_csv('data/ER/2018_n2c2/test_200_palm2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 GAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gad_df = pd.read_csv('data/ER/GAD/test_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_re_gad(sentence: str, shot: int = 0) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    chat = chat_model.start_chat(\n",
    "        context=\"\"\"\n",
    "                \"TASK: the task is to classify relations between a disease and a gene for a sentence.\"\n",
    "                \"INPUT: the input is a sentence where the disease is labeled as @DISEASE$ and the gene is labeled as @GENE$ accordingly in a sentence. \"\n",
    "                \"OUTPUT: your task is to select one out of the two types of relations (0 and 1) for the gene and disease without any explanation or other characters: \\n \\\n",
    "                        0, no relations \\n \\\n",
    "                        1, has relations\"\n",
    "                \"\"\",\n",
    "        examples=[\n",
    "            InputOutputTextPair(\n",
    "                input_text=\"We found evidence for association between @GENE$ and COGA @DISEASE$, history of blackouts, age at first drunkenness, and level of response to alcohol.\",\n",
    "                output_text='1',\n",
    "            ),\n",
    "        ] if shot == 1 else []\n",
    "    )\n",
    "\n",
    "    time_start = time.time()\n",
    "    response = chat.send_message(\n",
    "        sentence, **parameters\n",
    "    )\n",
    "    time_end = time.time()\n",
    "\n",
    "    return response.text, time_end - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(gad_df), 1)):\n",
    "    if (i + 1) % 20 == 0: # in case of quota limit error per minute\n",
    "        time.sleep(65)\n",
    "    gad_df.loc[i, 'palm2_zero_shot'], gad_df.loc[i, 'palm2_zero_shot_time'] = get_re_gad(gad_df.iloc[i]['text'], 0)\n",
    "    gad_df.loc[i, 'palm2_one_shot'], gad_df.loc[i, 'palm2_one_shot_time'] = get_re_gad(gad_df.iloc[i]['text'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert some strings to int while considering failed LLM outputs as 'No relation (0)'\n",
    "gad_df['palm2_zero_shot'] = gad_df['palm2_zero_shot'].apply(lambda x: int(x) if x.isdigit() else 0)\n",
    "gad_df['palm2_one_shot'] = gad_df['palm2_one_shot'].apply(lambda x: int(x) if x.isdigit() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: you can just load the llm output from the csv file instead of running the above code\n",
    "# gad_df = pd.read_csv(\"data/ER/GAD/test_200_palm2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gad_df['labels'].tolist()\n",
    "y_pred = gad_df['palm2_one_shot'].tolist()\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average PaLM 2 zero-shot prediction time: {gad_df['palm2_zero_shot_time'].mean():.2f} seconds\")\n",
    "print(f\"Average PaLM 2 one-shot prediction time: {gad_df['palm2_one_shot_time'].mean():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the inference results\n",
    "gad_df.to_csv('data/ER/GAD/test_200_palm2_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
